# -*- coding: utf-8 -*-
"""01_Quick_Pytorch

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uSsOikOvqrNM6GL39GgOVQ_wqeMgBrMn
"""

import torch

import numpy as np
data1 = np.array(10)
print(data1, data1.ndim, data1.shape)

data1 = torch.FloatTensor([1, 2])
print(data1, data1.dim(), data1.shape)

data2=torch.FloatTensor(3)
print(data2, data2.dim(), data2.shape)

data3 = torch.FloatTensor(3, 2)
print(data3, data3.dim(), data3.shape)

data4 = torch.FloatTensor([ [1,2], [3, 4], [5, 6]])
print(data4, data4.dim(), data4.shape)

data5 = torch.FloatTensor(3, 2, 1)
print(data5, data5.dim(), data5.shape)

data6 = torch.FloatTensor([ [ [1], [2]], [[3], [4]], [[5], [6] ] ])
print(data6, data6.dim(), data6.shape)

data7 = torch.FloatTensor([ [1], [2], [3]])
print(data7, data7.dim(), data7.shape)

data8 = torch.FloatTensor([ [1, 2, 3]])
print(data8, data8.dim(), data8.shape)

data1 = torch.zeros(2, dtype=torch.float)
data2 = torch.ones(2, 2, dtype=torch.double)
data3 = torch.rand(2, 2, 3 ,dtype=torch.half)
data4 = torch.randn(2, 2, 3, 4)
data5 = torch.full((2,4), 10)

print(data1.shape, data2.shape, data3.shape, data4.shape, data5.dtype)

print(data1.ndim, data2.ndim, data3.ndim, data4.ndim, data5.ndim)

print(data1.dim(), data2.dim(), data3.dim(), data4.dim(), data5.dim())

print(data1.dtype, data2.dtype, data3.dtype, data4.dtype, data5.dtype)

print(data1.size(), data2.size(), data3.size(), data4.size(), data5.size())

data6 = torch.FloatTensor([ [1, 2], [3, 4]])
data7 = torch.DoubleTensor([ [1, 2, 3], [4, 5, 6] ])
data8 = torch.LongTensor([ [1,2,3], [4, 5, 6], [7, 8, 9] ])

data9 = torch.FloatTensor(2, 3, 5)
data10 = torch.DoubleTensor(3, 3, 2, 4)
data11 = torch.LongTensor(4, 4)

data11

data12 = torch.full_like(data5, 20)
print(data5)
print(data12)

data1 = torch.DoubleTensor([[1,2,3],[4,5,6]])
print(data1, data1.shape)
data1=data1.reshape(3,2)
print(data1, data1.shape)
data1 = data1.reshape(2, -1)
print(data1, data1.shape)

data1 = torch.DoubleTensor([
    [[1, 2, 3],
     [4, 5, 6],
     [7, 8, 9],
     [10, 11, 12]]
])
print(data1.shape, "높이:", data1.size(0), "너비: ", data1.size(1), "깊이:", data1.size(2))

data1 = data1.view(2,-1)
print(data1, data1.shape)

data1 = data1.view(-1, 3)
print(data1, data1.shape)
data1 = data1.view(3, 2, -1)
print(data1, data1.shape)

data1.shape

data1 = torch.FloatTensor([[1],[2],[3]])
data2 = data1.squeeze()
print(data1, data1.dim())
print(data2, data2.dim())

data1 = torch.FloatTensor([ [1, 2, 3], [4, 5, 6]])
print(data1, data1.dim(), data1.shape)

data2 = data1.unsqueeze(0)
data3 = data1.unsqueeze(2)
print(data2, data2.dim(), data2.shape)
print(data3, data3.dim(), data3.shape)

data1 = torch.zeros(2, dtype=torch.float)
data2 = torch.ones(2, 4, dtype=torch.double)
data3 = torch.rand(2,2,3, dtype=torch.half)
print(data1.dtype, data2.dtype, data3.dtype)

data1=data1.type(torch.float32)
data2=data2.type(torch.int)
data3=data3.type(torch.double)
print(data1.dtype, data2.dtype, data3.dtype)

print(data2)

data2 = data2.T
print(data2)

data1 = np.array([[1,2],[3,4]])
print(data1, type(data1))
data2 = torch.from_numpy(data1)
print(data2, type(data2))
data3 = data2.numpy()
print(data3, type(data3))

torch.arange(5)

torch.arange(1,5)

torch.arange(1,5,2)

torch.linspace(1, 5, 4)

data1 = torch.full((3, 3), 2)
data2 = torch.full((3, 3), 1)
print(data1)
print(data2)
print(data1 + data2)
print(data1 - data2)
print(data1 * data2)
print(data2 / data2)

data1 = torch.full((3, 2), 2)
data2 = torch.full((2, 3), 1)
torch.matmul(data1, data2)

data1 = torch.torch.FloatTensor([ 
                              [1], 
                               [2], 
                                [3]
                                          ])
data2 = torch.FloatTensor([1, 1, 1])
data3 = data1 + data2
print(data1.shape, data2.shape, data3.shape)

data1 = torch.torch.FloatTensor(10,1,4)
data2 = torch.FloatTensor(10, 2, 1)
data3 = data1 + data2
print(data1.shape, data2.shape, data3.shape)

data1 = torch.torch.FloatTensor(5)
data2 = torch.FloatTensor(10, 10, 1)
data3 = data1 * data2
print(data1.shape, data2.shape, data3.shape)

data3 = torch.FloatTensor([ [1, 2, 3],
                           [4, 5, 6]])
print(data3)
print(data3[1, 1])
print(data3[:, 1])
print(data3[:, :])
print(data3[:1, :2])

data1 = torch.FloatTensor([ [1, 2, 3], [5, 5, 5]])
data2 = data1 > 3
print(data2)
print(data1[data2])
print(data1[(data1 > 3) & (data1 < 5)])

data1 = torch.randn(4, 3)
print(data1)

print(data1[[1, 2, 0]])
print(data1[ [1, -1]])

print(data1[ [1,2] ][:, [0, 2]])

print(data1[[1, -1]][:, [0]])

data1 = torch.FloatTensor([ [1,2,3], [4, 5, 6]])
print(data1)
data2 = data1[:2, :2]
print(data2)

data2[1, 1] = 4
print(data2);print(data1)

data1 = torch.FloatTensor([ [1,2,3], [4,5,6]])
print(data1)
data2 = data1[:2, :2].clone().detach()
print(data2)
data2[0][1] = 7
print(data1)
print(data2)

data1 = torch.FloatTensor([7,2,0,4,1])
index= torch.where(data1 < 3)
print(index)
print(data1[index])

print(data1)
data2 = torch.where(data1 < 3, -1, 1)
print(data2)

data1 = torch.FloatTensor( [ 
                          [1, 2, 3],
                          [4, 5, 6]
                                    ])
data2 = torch.where(data1 < 3, -1, 1)
print(data2)

data1 = torch.FloatTensor([[1,2,3],
                           [4, 5, 6]])
print(data1.min())
print(data1.max())
print(data1.sum())
print(data1.mean())
print(data1.var())
print(data1.argmin())
print(data1.argmax())
print(data1.std())

data1 = torch.linspace(1, 5, 4)
print(data1)
torch.save(data1, 'mydata1.pt')

torch.load('mydata1.pt')

