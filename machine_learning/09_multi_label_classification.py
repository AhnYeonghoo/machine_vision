# -*- coding: utf-8 -*-
"""09_multi_label_classification

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ROj_8Bn8ZtD7zZMeKk20-91kV9aolb39
"""

import torch
import torch.nn as nn
import numpy as np
import pandas as pd

from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

iris = load_iris()
x = iris['data']
y = iris['target']
names = iris['target_names']
feature_names = iris['feature_names']

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)

iris['target']

std_scaler = StandardScaler()
std_scaler.fit(x_train)
x_train_tensor = torch.from_numpy(std_scaler.transform(x_train)).float()
x_test_tensor = torch.from_numpy(std_scaler.transform(x_test)).float()
y_train_tensor = torch.from_numpy(y_train).long()
y_test_tensor = torch.from_numpy(y_test).long()

print(x_train_tensor.shape, x_test_tensor.shape, y_train_tensor.shape, y_test_tensor.shape)

epochs = 1000
minibatch_size = 120

class FunModel(nn.Module):
  def __init__(self, input, output):
    super().__init__()
    self.linear_layers = nn.Sequential(
        nn.Linear(input, 100),
        nn.LeakyReLU(0.1),
        nn.Linear(100, 20),
        nn.LeakyReLU(0.1),
        nn.Linear(20, 5),
        nn.LeakyReLU(0.1),
        nn.Linear(5, output),
        nn.LogSoftmax(dim=-1)
    )

  def forward(self,x):
    return self.linear_layers(x)
  
input = x_train_tensor.size(-1)
output = 3
print(input, output)
model = FunModel(input, output)
loss_func = nn.NLLLoss()
optimizer = torch.optim.Adam(model.parameters())

