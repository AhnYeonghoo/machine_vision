# -*- coding: utf-8 -*-
"""08_simple_actual_example_binary_classification

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1THldyo_qGeaF3N4MfqKpwB7XDOy6T28t
"""

import torch
import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler

df_data = pd.read_csv('dataset_phishing.csv')
df_data.shape

df_data['status']

df_data['target'] = pd.get_dummies(df_data['status'])['legitimate'].astype('int')
df_data.drop('status', axis=1, inplace=True)
df_data[['url', 'target']].head(5)

from sklearn.model_selection  import train_test_split

X = df_data.iloc[:, 1:-1]
y = df_data['target']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)
print(X_train.shape, y_train.shape)
print(X_test.shape, y_test.shape)

y_train

X_train.head()

std_scaler = StandardScaler()
std_scaler.fit(X_train)
X_train_tensor = torch.from_numpy(std_scaler.transform(X_train)).float()
X_test_tensor = torch.from_numpy(std_scaler.transform(X_test)).float()
y_train_tensor =torch.from_numpy(y_train.values).float()
y_train_tensor = y_train_tensor.unsqueeze(1)
y_test_tensor = torch.from_numpy(y_test.values).float()
y_test_tensor = y_test_tensor.unsqueeze(1)
epochs = 1000
batch_size = 256
import torch.nn as nn
import torch.functional as F

class FunModel(nn.Module):
  def __init__(self, input, output):
    super().__init__()

    self.linear_layers = nn.Sequential(
        nn.Linear(input, 200),
        nn.LeakyReLU(0.1),
        nn.Linear(200, 100),
        nn.LeakyReLU(0.1),
        nn.Linear(100, 20),
        nn.LeakyReLU(0.1),
        nn.Linear(20, 5),
        nn.LeakyReLU(0.1),
        nn.Linear(5, output),
        nn.Sigmoid()
    )
  
  def forward(self, x):
    y = self.linear_layers(x)
    return y

input = X_train_tensor.size(-1)
output = y_train_tensor.size(-1)
print(input, output)

model = FunModel(input, output)
loss_func = nn.BCELoss()
optimizer = torch.optim.Adam(model.parameters())

for index in range(epochs):
  indices = torch.randperm(X_train_tensor.size(0))

  x_batch_list = torch.index_select(X_train_tensor, 0, index=indices)
  y_batch_list = torch.index_select(y_train_tensor, 0, index=indices)
  x_batch_list = x_batch_list.split(batch_size, 0)
  y_batch_list = y_batch_list.split(batch_size, 0)
  epoch_loss = list()
  
  for x, y in zip(x_batch_list, y_batch_list):
    y_pred = model(x)
    
    loss = loss_func(y_pred, y)
    epoch_loss.append(loss)

    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

  if (index % 100) == 0:
    print(index, sum(epoch_loss) / len(epoch_loss))

y_pred_list = []
model.eval()
with torch.no_grad():
  y_test_pred_sigmoid = model(X_test_tensor)
  y_test_pred = torch.round(y_test_pred_sigmoid)

y_test_pred

from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score

